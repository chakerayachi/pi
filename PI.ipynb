{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('chaker.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Concept</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>definitions</th>\n",
       "      <th>similarity</th>\n",
       "      <th>Verbe</th>\n",
       "      <th>noed_connected</th>\n",
       "      <th>key_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plan risk management</td>\n",
       "      <td>plan risk management be the process of define ...</td>\n",
       "      <td>how to conduct risk management activity for a ...</td>\n",
       "      <td>['risk management plan', 'plan risk response']</td>\n",
       "      <td>be</td>\n",
       "      <td>['risk management plan', 'project management p...</td>\n",
       "      <td>['risk', 'management', 'plan', 'process', 'sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>project charter</td>\n",
       "      <td>describe in section 4.1.3.1 . the project char...</td>\n",
       "      <td>high - level project description and boundary</td>\n",
       "      <td>[]</td>\n",
       "      <td>document</td>\n",
       "      <td>['project document', 'project document', 'proj...</td>\n",
       "      <td>['charter', 'section', 'description', 'project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>project management plan</td>\n",
       "      <td>describe in section 4.2.3.1 . in planning proj...</td>\n",
       "      <td>subsidiary management plan</td>\n",
       "      <td>['project management plan', 'project managemen...</td>\n",
       "      <td>planning</td>\n",
       "      <td>['risk management plan', 'project management p...</td>\n",
       "      <td>['risk', 'outline', 'planning', 'subsidiary', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>project document</td>\n",
       "      <td>project document that can be consider as input...</td>\n",
       "      <td>stakeholder</td>\n",
       "      <td>['project document', 'project document update'...</td>\n",
       "      <td>be</td>\n",
       "      <td>['project document', 'project document', 'proj...</td>\n",
       "      <td>['stakeholder', 'risk', 'responsibility', 'ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enterprise environmental factor</td>\n",
       "      <td>the enterprise environmental factor that can i...</td>\n",
       "      <td>overall risk threshold set by the organization...</td>\n",
       "      <td>['enterprise environmental factor', 'enterpris...</td>\n",
       "      <td>influence</td>\n",
       "      <td>['enterprise environmental factor', 'enterpris...</td>\n",
       "      <td>['risk', 'environmental', 'enterprise', 'stake...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Concept  \\\n",
       "0             plan risk management   \n",
       "1                  project charter   \n",
       "2          project management plan   \n",
       "3                 project document   \n",
       "4  enterprise environmental factor   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  plan risk management be the process of define ...   \n",
       "1  describe in section 4.1.3.1 . the project char...   \n",
       "2  describe in section 4.2.3.1 . in planning proj...   \n",
       "3  project document that can be consider as input...   \n",
       "4  the enterprise environmental factor that can i...   \n",
       "\n",
       "                                         definitions  \\\n",
       "0  how to conduct risk management activity for a ...   \n",
       "1      high - level project description and boundary   \n",
       "2                         subsidiary management plan   \n",
       "3                                        stakeholder   \n",
       "4  overall risk threshold set by the organization...   \n",
       "\n",
       "                                          similarity      Verbe  \\\n",
       "0     ['risk management plan', 'plan risk response']         be   \n",
       "1                                                 []   document   \n",
       "2  ['project management plan', 'project managemen...   planning   \n",
       "3  ['project document', 'project document update'...         be   \n",
       "4  ['enterprise environmental factor', 'enterpris...  influence   \n",
       "\n",
       "                                      noed_connected  \\\n",
       "0  ['risk management plan', 'project management p...   \n",
       "1  ['project document', 'project document', 'proj...   \n",
       "2  ['risk management plan', 'project management p...   \n",
       "3  ['project document', 'project document', 'proj...   \n",
       "4  ['enterprise environmental factor', 'enterpris...   \n",
       "\n",
       "                                            key_list  \n",
       "0  ['risk', 'management', 'plan', 'process', 'sta...  \n",
       "1  ['charter', 'section', 'description', 'project...  \n",
       "2  ['risk', 'outline', 'planning', 'subsidiary', ...  \n",
       "3  ['stakeholder', 'risk', 'responsibility', 'ove...  \n",
       "4  ['risk', 'environmental', 'enterprise', 'stake...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_1712\\3314729575.py:1: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  df.fillna(method='bfill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df.fillna(method='bfill', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'Concept': 'subject'}, inplace=True)\n",
    "df.rename(columns={'Verbe': 'predicate'}, inplace=True)\n",
    "df.rename(columns={'definitions': 'object'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>paragraph</th>\n",
       "      <th>object</th>\n",
       "      <th>similarity</th>\n",
       "      <th>predicate</th>\n",
       "      <th>noed_connected</th>\n",
       "      <th>key_list</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plan risk management</td>\n",
       "      <td>plan risk management be the process of define ...</td>\n",
       "      <td>how to conduct risk management activity for a ...</td>\n",
       "      <td>['risk management plan', 'plan risk response']</td>\n",
       "      <td>be</td>\n",
       "      <td>['risk management plan', 'project management p...</td>\n",
       "      <td>['risk', 'management', 'plan', 'process', 'sta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>project charter</td>\n",
       "      <td>describe in section 4.1.3.1 . the project char...</td>\n",
       "      <td>high - level project description and boundary</td>\n",
       "      <td>[]</td>\n",
       "      <td>document</td>\n",
       "      <td>['project document', 'project document', 'proj...</td>\n",
       "      <td>['charter', 'section', 'description', 'project...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>project management plan</td>\n",
       "      <td>describe in section 4.2.3.1 . in planning proj...</td>\n",
       "      <td>subsidiary management plan</td>\n",
       "      <td>['project management plan', 'project managemen...</td>\n",
       "      <td>planning</td>\n",
       "      <td>['risk management plan', 'project management p...</td>\n",
       "      <td>['risk', 'outline', 'planning', 'subsidiary', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>project document</td>\n",
       "      <td>project document that can be consider as input...</td>\n",
       "      <td>stakeholder</td>\n",
       "      <td>['project document', 'project document update'...</td>\n",
       "      <td>be</td>\n",
       "      <td>['project document', 'project document', 'proj...</td>\n",
       "      <td>['stakeholder', 'risk', 'responsibility', 'ove...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>enterprise environmental factor</td>\n",
       "      <td>the enterprise environmental factor that can i...</td>\n",
       "      <td>overall risk threshold set by the organization...</td>\n",
       "      <td>['enterprise environmental factor', 'enterpris...</td>\n",
       "      <td>influence</td>\n",
       "      <td>['enterprise environmental factor', 'enterpris...</td>\n",
       "      <td>['risk', 'environmental', 'enterprise', 'stake...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           subject  \\\n",
       "0             plan risk management   \n",
       "1                  project charter   \n",
       "2          project management plan   \n",
       "3                 project document   \n",
       "4  enterprise environmental factor   \n",
       "\n",
       "                                           paragraph  \\\n",
       "0  plan risk management be the process of define ...   \n",
       "1  describe in section 4.1.3.1 . the project char...   \n",
       "2  describe in section 4.2.3.1 . in planning proj...   \n",
       "3  project document that can be consider as input...   \n",
       "4  the enterprise environmental factor that can i...   \n",
       "\n",
       "                                              object  \\\n",
       "0  how to conduct risk management activity for a ...   \n",
       "1      high - level project description and boundary   \n",
       "2                         subsidiary management plan   \n",
       "3                                        stakeholder   \n",
       "4  overall risk threshold set by the organization...   \n",
       "\n",
       "                                          similarity  predicate  \\\n",
       "0     ['risk management plan', 'plan risk response']         be   \n",
       "1                                                 []   document   \n",
       "2  ['project management plan', 'project managemen...   planning   \n",
       "3  ['project document', 'project document update'...         be   \n",
       "4  ['enterprise environmental factor', 'enterpris...  influence   \n",
       "\n",
       "                                      noed_connected  \\\n",
       "0  ['risk management plan', 'project management p...   \n",
       "1  ['project document', 'project document', 'proj...   \n",
       "2  ['risk management plan', 'project management p...   \n",
       "3  ['project document', 'project document', 'proj...   \n",
       "4  ['enterprise environmental factor', 'enterpris...   \n",
       "\n",
       "                                            key_list  \n",
       "0  ['risk', 'management', 'plan', 'process', 'sta...  \n",
       "1  ['charter', 'section', 'description', 'project...  \n",
       "2  ['risk', 'outline', 'planning', 'subsidiary', ...  \n",
       "3  ['stakeholder', 'risk', 'responsibility', 'ove...  \n",
       "4  ['risk', 'environmental', 'enterprise', 'stake...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = df.apply(lambda row: (row['subject'], row['predicate'], row['object']), axis=1).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Triples:\n",
      "('perform quantitative risk analysis', 'be', 'plan risk response process')\n",
      "('expert judgment', 'be', 'bias')\n",
      "('risk categorization', 'be', 'common root cause')\n",
      "('datum gathering', 'be', 'individual project risk and other source of uncertainty')\n",
      "('expert judgment', 'be', 'specialized knowledge')\n",
      "('organizational process asset', 'include', 'project file')\n",
      "('enterprise environmental factor', 'include', 'industry study of similar project')\n",
      "('interpersonal and team skill', 'be', 'facilitation')\n",
      "('data analysis', 'be', 'stakeholder analysis')\n",
      "('project document update', 'be', 'risk report')\n",
      "('strategy for overall project risk', 'be', 'avoid')\n",
      "('datum analysis', 'be', 'root cause analysis')\n",
      "('interpersonal and team skill', 'be', 'influence')\n",
      "('project document update', 'be', 'assumption log .')\n",
      "('representation of uncertainty', 'be', 'probability distribution')\n",
      "('agreement', 'require', 'milestone date , contract type , acceptance criterion , and award and penalty')\n",
      "('risk report', 'be', 'source of overall project risk')\n",
      "('project document', 'be', 'stakeholder')\n",
      "('expert judgment', 'be', 'expert ’ bias')\n",
      "('project document update', 'be', 'assumption log')\n",
      "('meeting', 'be', '\\n plan for conduct risk management activity')\n",
      "('project document', 'be', 'lesson learn register')\n",
      "('expert judgment', 'be', 'familiarity with the organization ’s approach to manage risk')\n",
      "('datum gathering', 'be', 'interview')\n",
      "('datum representation', 'be', 'three dimension')\n",
      "('project document', 'be', 'issue log')\n",
      "('project document update', 'be', 'assumption log')\n",
      "('organizational process asset', 'influence', 'historical database')\n",
      "('organizational process asset', 'influence', '\\n information from similar complete project')\n",
      "('plan risk response', 'be', 'the process of develop option , select strategy , and agree on action')\n",
      "('interpersonal and team skill', 'be', 'facilitation')\n",
      "('project management plan update', 'go', 'change \\n request')\n",
      "('enterprise environmental factor', 'include', 'publish material')\n",
      "('organizational process asset', 'influence', 'lesson learn repository')\n",
      "('project management plan', 'be', 'risk management plan')\n",
      "('project document', 'be', 'assumption log')\n",
      "('datum analysis', 'be', 'alternative analysis')\n",
      "('strategy for threat', 'be', 'escalate')\n",
      "('data analysis', 'be', 'simulation')\n",
      "('project management plan', 'be', 'risk')\n",
      "('interpersonal and team skill', 'be', 'facilitation')\n",
      "('datum gathering', 'be', 'semi - structured interview')\n",
      "('meeting', 'be', 'risk review')\n",
      "('strategy for opportunity', 'be', 'escalate')\n",
      "('decision make', 'be', 'multicriteria decision analysis')\n",
      "('project document update', 'be', 'issue log')\n",
      "('meeting', 'be', 'a risk \\n workshop')\n",
      "('enterprise environmental factor', 'include', 'industry study of similar project')\n",
      "('project charter', 'document', 'high - level project description and boundary')\n",
      "('project document', 'be', 'lesson learn register')\n",
      "('prompt list', 'be', 'a predetermined list of risk category that might give rise to individual project risk')\n",
      "('project management plan', 'planning', 'subsidiary management plan')\n",
      "('risk register', 'be', 'management plan')\n",
      "('datum analysis', 'be', 'objective , quantifiable')\n",
      "('change request', 'result', 'process for review')\n",
      "('audits', 'be', 'risk audits')\n",
      "('interpersonal and team skill', 'be', 'facilitation')\n",
      "('contingent response strategy', 'be', 'fallback plan')\n",
      "('expert judgment', 'be', 'efficient and effective manner')\n",
      "('procurement documentation', 'be', 'procure good and service from outside the organization')\n",
      "('project management plan', 'be', 'resource management plan')\n",
      "\n",
      "Testing Triples:\n",
      "('monitor risk', 'be', 'the process of monitor the implementation of agree - upon risk response plan')\n",
      "('plan risk management', 'be', 'how to conduct risk management activity for a project')\n",
      "('perform qualitative risk analysis', 'be', 'the risk management plan')\n",
      "('meeting', 'be', 'risk workshop')\n",
      "('project document', 'be', 'assumption log')\n",
      "('implement risk response', 'be', 'the process of implement agree - upon risk response plan')\n",
      "('identify risk', 'be', 'individual project risk')\n",
      "('datum gathering', 'be', 'brainstorming')\n",
      "('enterprise environmental factor', 'influence', 'overall risk threshold set by the organization or key stakeholder')\n",
      "('project management plan', 'be', 'risk \\n management plan')\n",
      "('change request', 'address', 'process for review and \\n disposition through the perform integrate change control process')\n",
      "('project management plan update', 'be', 'scope baseline')\n",
      "('enterprise environmental factor', 'influence', 'risk appetite and threshold of key stakeholder')\n",
      "('work performance report', 'provide', 'performance measurement')\n",
      "('work performance information', 'occur', 'information on how project risk management')\n",
      "('change request', 'risk', 'process for review and \\n disposition through the perform integrate change control process')\n",
      "('datum analysis', 'be', 'risk management')\n",
      "('work performance datum', 'have', 'datum on project status')\n",
      "('expert judgment', 'be', 'specialized knowledge')\n",
      "('project management information system ( pmis )', 'include', 'schedule , resource , and cost')\n",
      "('project management plan', 'be', 'requirement management plan')\n",
      "('organizational process asset', 'influence', '\\n information from similar complete project')\n",
      "('project management plan', 'be', 'risk management plan')\n",
      "('project document', 'be', 'assumption log')\n",
      "('risk management plan', 'be', 'risk strategy')\n",
      "('project document update', 'be', 'assumption log')\n",
      "('organizational process asset', 'influence', 'organizational risk policy')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming you have a list of triples (subject, predicate, object)\n",
    "\n",
    "# Split the triples into subject, predicate, and object lists\n",
    "subjects, predicates, objects = zip(*triples)\n",
    "\n",
    "# Split the data into training and testing sets using random split\n",
    "train_subjects, test_subjects, train_predicates, test_predicates, train_objects, test_objects = train_test_split(subjects, predicates, objects, test_size=0.3, random_state=42)\n",
    "\n",
    "# Print the training and testing triples\n",
    "train_triples = list(zip(train_subjects, train_predicates, train_objects))\n",
    "test_triples = list(zip(test_subjects, test_predicates, test_objects))\n",
    "\n",
    "print(\"Training Triples:\")\n",
    "for triple in train_triples:\n",
    "    print(triple)\n",
    "\n",
    "print(\"\\nTesting Triples:\")\n",
    "for triple in test_triples:\n",
    "    print(triple)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Define the KnowledgeGraph dataset class\n",
    "class KnowledgeGraphDataset(Dataset):\n",
    "    def __init__(self, triples, entity2idx, relation2idx):\n",
    "        self.triples = triples\n",
    "        self.entity2idx = entity2idx\n",
    "        self.relation2idx = relation2idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subject, relation, object_ = self.triples[idx]\n",
    "        return self.entity2idx[subject], self.relation2idx[relation], self.entity2idx[object_]\n",
    "\n",
    "# Define the TransE model\n",
    "class TransE(nn.Module):\n",
    "    def __init__(self, num_entities, num_relations, embedding_dim):\n",
    "        super(TransE, self).__init__()\n",
    "        self.num_entities = num_entities\n",
    "        self.num_relations = num_relations\n",
    "        self.embedding_dim = embedding_dim\n",
    "\n",
    "        self.entity_embeddings = nn.Embedding(num_entities, embedding_dim)\n",
    "        self.relation_embeddings = nn.Embedding(num_relations, embedding_dim)\n",
    "\n",
    "    def forward(self, sample):\n",
    "        subject = self.entity_embeddings(sample[:, 0])\n",
    "        relation = self.relation_embeddings(sample[:, 1])\n",
    "        object_ = self.entity_embeddings(sample[:, 2])\n",
    "\n",
    "        return subject, relation, object_\n",
    "\n",
    "# Create a list of triples (subject, relation, object)\n",
    "\n",
    "# Map entities and relations to numerical indices\n",
    "entities = list(set([subject for subject, _, _ in triples] + [object_ for _, _, object_ in triples]))\n",
    "entity2idx = {entity: idx for idx, entity in enumerate(entities)}\n",
    "relations = list(set([relation for _, relation, _ in triples]))\n",
    "relation2idx = {relation: idx for idx, relation in enumerate(relations)}\n",
    "\n",
    "# Define the KnowledgeGraph dataset\n",
    "dataset = KnowledgeGraphDataset(triples, entity2idx, relation2idx)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\anaconda3\\envs\\PI\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.6761\n",
      "Epoch: 0, Loss: 1.4875\n",
      "Epoch: 0, Loss: 1.8762\n",
      "Epoch: 0, Loss: 1.9638\n",
      "Epoch: 0, Loss: 1.3489\n",
      "Epoch: 0, Loss: 1.4668\n",
      "Epoch: 0, Loss: 0.9840\n",
      "Epoch: 0, Loss: 1.0341\n",
      "Epoch: 0, Loss: 1.6594\n",
      "Epoch: 0, Loss: 1.6602\n",
      "Epoch: 0, Loss: 1.2669\n",
      "Epoch: 0, Loss: 1.3651\n",
      "Epoch: 0, Loss: 1.4549\n",
      "Epoch: 0, Loss: 1.3487\n",
      "Epoch: 0, Loss: 0.8728\n",
      "Epoch: 0, Loss: 1.6423\n",
      "Epoch: 0, Loss: 0.5961\n",
      "Epoch: 0, Loss: 1.8930\n",
      "Epoch: 0, Loss: 1.5476\n",
      "Epoch: 0, Loss: 1.2612\n",
      "Epoch: 0, Loss: 1.1576\n",
      "Epoch: 0, Loss: 1.2919\n",
      "Epoch: 0, Loss: 0.7792\n",
      "Epoch: 0, Loss: 1.1941\n",
      "Epoch: 0, Loss: 1.6547\n",
      "Epoch: 0, Loss: 0.8255\n",
      "Epoch: 0, Loss: 1.0802\n",
      "Epoch: 0, Loss: 1.2529\n",
      "Epoch: 0, Loss: 1.1799\n",
      "Epoch: 0, Loss: 0.7075\n",
      "Epoch: 0, Loss: 1.5714\n",
      "Epoch: 0, Loss: 0.8234\n",
      "Epoch: 0, Loss: 1.8018\n",
      "Epoch: 0, Loss: 0.5938\n",
      "Epoch: 0, Loss: 1.8328\n",
      "Epoch: 0, Loss: 0.3217\n",
      "Epoch: 0, Loss: 0.9821\n",
      "Epoch: 0, Loss: 1.0110\n",
      "Epoch: 0, Loss: 1.4407\n",
      "Epoch: 0, Loss: 0.9164\n",
      "Epoch: 0, Loss: 1.1977\n",
      "Epoch: 0, Loss: 1.4429\n",
      "Epoch: 0, Loss: 1.3473\n",
      "Epoch: 0, Loss: 1.1625\n",
      "Epoch: 1, Loss: 1.0810\n",
      "Epoch: 1, Loss: 0.7327\n",
      "Epoch: 1, Loss: 1.3735\n",
      "Epoch: 1, Loss: 0.8445\n",
      "Epoch: 1, Loss: 1.1708\n",
      "Epoch: 1, Loss: 1.5007\n",
      "Epoch: 1, Loss: 1.1569\n",
      "Epoch: 1, Loss: 1.1107\n",
      "Epoch: 1, Loss: 0.8719\n",
      "Epoch: 1, Loss: 1.8641\n",
      "Epoch: 1, Loss: 1.2893\n",
      "Epoch: 1, Loss: 1.3741\n",
      "Epoch: 1, Loss: 1.2738\n",
      "Epoch: 1, Loss: 0.6874\n",
      "Epoch: 1, Loss: 0.9714\n",
      "Epoch: 1, Loss: 1.2641\n",
      "Epoch: 1, Loss: 1.4935\n",
      "Epoch: 1, Loss: 0.5789\n",
      "Epoch: 1, Loss: 1.0397\n",
      "Epoch: 1, Loss: 1.3212\n",
      "Epoch: 1, Loss: 1.0174\n",
      "Epoch: 1, Loss: 1.6700\n",
      "Epoch: 1, Loss: 1.4156\n",
      "Epoch: 1, Loss: 1.5983\n",
      "Epoch: 1, Loss: 1.2027\n",
      "Epoch: 1, Loss: 1.1503\n",
      "Epoch: 1, Loss: 0.7018\n",
      "Epoch: 1, Loss: 1.0787\n",
      "Epoch: 1, Loss: 0.6176\n",
      "Epoch: 1, Loss: 0.3978\n",
      "Epoch: 1, Loss: 0.9469\n",
      "Epoch: 1, Loss: 1.0585\n",
      "Epoch: 1, Loss: 1.0646\n",
      "Epoch: 1, Loss: 0.8942\n",
      "Epoch: 1, Loss: 0.7969\n",
      "Epoch: 1, Loss: 1.0699\n",
      "Epoch: 1, Loss: 1.7100\n",
      "Epoch: 1, Loss: 2.3642\n",
      "Epoch: 1, Loss: 0.9181\n",
      "Epoch: 1, Loss: 1.1268\n",
      "Epoch: 1, Loss: 0.7601\n",
      "Epoch: 1, Loss: 2.1179\n",
      "Epoch: 1, Loss: 0.6869\n",
      "Epoch: 1, Loss: 0.9163\n",
      "Epoch: 2, Loss: 1.2948\n",
      "Epoch: 2, Loss: 1.2255\n",
      "Epoch: 2, Loss: 1.8147\n",
      "Epoch: 2, Loss: 0.8467\n",
      "Epoch: 2, Loss: 1.9150\n",
      "Epoch: 2, Loss: 1.6106\n",
      "Epoch: 2, Loss: 1.0027\n",
      "Epoch: 2, Loss: 1.1611\n",
      "Epoch: 2, Loss: 0.7051\n",
      "Epoch: 2, Loss: 1.1855\n",
      "Epoch: 2, Loss: 1.3450\n",
      "Epoch: 2, Loss: 0.8465\n",
      "Epoch: 2, Loss: 1.2985\n",
      "Epoch: 2, Loss: 0.7999\n",
      "Epoch: 2, Loss: 1.5941\n",
      "Epoch: 2, Loss: 0.6984\n",
      "Epoch: 2, Loss: 0.5223\n",
      "Epoch: 2, Loss: 1.0478\n",
      "Epoch: 2, Loss: 0.9346\n",
      "Epoch: 2, Loss: 1.0685\n",
      "Epoch: 2, Loss: 1.4555\n",
      "Epoch: 2, Loss: 0.7862\n",
      "Epoch: 2, Loss: 1.2627\n",
      "Epoch: 2, Loss: 1.7169\n",
      "Epoch: 2, Loss: 0.7305\n",
      "Epoch: 2, Loss: 1.5586\n",
      "Epoch: 2, Loss: 0.8935\n",
      "Epoch: 2, Loss: 0.8600\n",
      "Epoch: 2, Loss: 1.1617\n",
      "Epoch: 2, Loss: 1.0058\n",
      "Epoch: 2, Loss: 0.6252\n",
      "Epoch: 2, Loss: 0.7307\n",
      "Epoch: 2, Loss: 1.1197\n",
      "Epoch: 2, Loss: 1.6115\n",
      "Epoch: 2, Loss: 1.7124\n",
      "Epoch: 2, Loss: 0.5322\n",
      "Epoch: 2, Loss: 1.2456\n",
      "Epoch: 2, Loss: 0.6552\n",
      "Epoch: 2, Loss: 1.2291\n",
      "Epoch: 2, Loss: 1.3006\n",
      "Epoch: 2, Loss: 1.2872\n",
      "Epoch: 2, Loss: 1.0088\n",
      "Epoch: 2, Loss: 1.2152\n",
      "Epoch: 2, Loss: 0.6833\n"
     ]
    }
   ],
   "source": [
    "# Define the dataloader\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "# Set the hyperparameters\n",
    "num_entities = len(entities)\n",
    "num_relations = len(relations)\n",
    "embedding_dim = 3\n",
    "learning_rate = 0.02\n",
    "num_epochs = 3\n",
    "\n",
    "# Define the TransE model\n",
    "model = TransE(num_entities, num_relations, embedding_dim)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.MarginRankingLoss(margin=1.0)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Positive samples\n",
    "        positive_samples = torch.stack(batch, dim=1).long()\n",
    "\n",
    "        # Generate negative samples by corrupting the objects in positive samples\n",
    "        negative_samples = positive_samples.clone()\n",
    "\n",
    "\n",
    "        negative_samples[:, 2] = torch.randint(num_entities, size=(negative_samples.size(0),))\n",
    "\n",
    "        # Forward pass\n",
    "        pos_subject, pos_relation, pos_object = model(positive_samples)\n",
    "        neg_subject, neg_relation, neg_object = model(negative_samples)\n",
    "\n",
    "        # Compute the loss\n",
    "        # Compute the loss\n",
    "        target = torch.ones(pos_subject.size(0), 1)\n",
    "        loss = criterion(pos_subject + pos_relation - pos_object, neg_subject + neg_relation - neg_object, target)\n",
    "\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"Epoch: {}, Loss: {:.4f}\".format(epoch, loss.item()))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "110"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(entities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.0483\n",
      "Epoch: 0, Loss: 2.0341\n",
      "Epoch: 0, Loss: 1.6574\n",
      "Epoch: 0, Loss: 1.1612\n",
      "Epoch: 0, Loss: 1.3850\n",
      "Epoch: 0, Loss: 0.1536\n",
      "Epoch: 0, Loss: 1.2455\n",
      "Epoch: 0, Loss: 0.6926\n",
      "Epoch: 0, Loss: 0.8680\n",
      "Epoch: 0, Loss: 0.9280\n",
      "Epoch: 0, Loss: 1.0246\n",
      "Epoch: 0, Loss: 1.7262\n",
      "Epoch: 0, Loss: 1.1609\n",
      "Epoch: 0, Loss: 0.4728\n",
      "Epoch: 0, Loss: 1.7330\n",
      "Epoch: 0, Loss: 0.9392\n",
      "Epoch: 0, Loss: 1.1335\n",
      "Epoch: 0, Loss: 1.5390\n",
      "Epoch: 0, Loss: 1.0670\n",
      "Epoch: 0, Loss: 1.1722\n",
      "Epoch: 0, Loss: 0.7306\n",
      "Epoch: 0, Loss: 1.5657\n",
      "Epoch: 0, Loss: 0.7061\n",
      "Epoch: 0, Loss: 1.0272\n",
      "Epoch: 0, Loss: 0.7356\n",
      "Epoch: 0, Loss: 1.5244\n",
      "Epoch: 0, Loss: 1.9778\n",
      "Epoch: 0, Loss: 2.2379\n",
      "Epoch: 0, Loss: 1.8804\n",
      "Epoch: 0, Loss: 0.7311\n",
      "Epoch: 0, Loss: 0.6241\n",
      "Epoch: 1, Loss: 1.3139\n",
      "Epoch: 1, Loss: 1.0692\n",
      "Epoch: 1, Loss: 1.1170\n",
      "Epoch: 1, Loss: 0.7119\n",
      "Epoch: 1, Loss: 2.0020\n",
      "Epoch: 1, Loss: 0.9712\n",
      "Epoch: 1, Loss: 2.2749\n",
      "Epoch: 1, Loss: 1.5881\n",
      "Epoch: 1, Loss: 1.3175\n",
      "Epoch: 1, Loss: 1.8236\n",
      "Epoch: 1, Loss: 1.5045\n",
      "Epoch: 1, Loss: 1.1171\n",
      "Epoch: 1, Loss: 1.3737\n",
      "Epoch: 1, Loss: 0.6251\n",
      "Epoch: 1, Loss: 1.3022\n",
      "Epoch: 1, Loss: 1.2457\n",
      "Epoch: 1, Loss: 1.4886\n",
      "Epoch: 1, Loss: 1.5206\n",
      "Epoch: 1, Loss: 1.7570\n",
      "Epoch: 1, Loss: 1.5032\n",
      "Epoch: 1, Loss: 1.0389\n",
      "Epoch: 1, Loss: 2.1398\n",
      "Epoch: 1, Loss: 1.3824\n",
      "Epoch: 1, Loss: 2.3648\n",
      "Epoch: 1, Loss: 0.7544\n",
      "Epoch: 1, Loss: 1.4441\n",
      "Epoch: 1, Loss: 0.2949\n",
      "Epoch: 1, Loss: 0.8292\n",
      "Epoch: 1, Loss: 1.6902\n",
      "Epoch: 1, Loss: 0.5101\n",
      "Epoch: 1, Loss: 0.1759\n",
      "Epoch: 2, Loss: 1.2841\n",
      "Epoch: 2, Loss: 0.8257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Loss: 0.8047\n",
      "Epoch: 2, Loss: 2.2006\n",
      "Epoch: 2, Loss: 1.3792\n",
      "Epoch: 2, Loss: 1.2950\n",
      "Epoch: 2, Loss: 1.3786\n",
      "Epoch: 2, Loss: 1.6529\n",
      "Epoch: 2, Loss: 1.0827\n",
      "Epoch: 2, Loss: 0.9996\n",
      "Epoch: 2, Loss: 1.1672\n",
      "Epoch: 2, Loss: 0.1271\n",
      "Epoch: 2, Loss: 0.9759\n",
      "Epoch: 2, Loss: 1.0903\n",
      "Epoch: 2, Loss: 0.6554\n",
      "Epoch: 2, Loss: 0.9782\n",
      "Epoch: 2, Loss: 0.9901\n",
      "Epoch: 2, Loss: 1.1034\n",
      "Epoch: 2, Loss: 0.7452\n",
      "Epoch: 2, Loss: 1.3436\n",
      "Epoch: 2, Loss: 1.0710\n",
      "Epoch: 2, Loss: 1.4906\n",
      "Epoch: 2, Loss: 0.8388\n",
      "Epoch: 2, Loss: 1.8857\n",
      "Epoch: 2, Loss: 1.5333\n",
      "Epoch: 2, Loss: 1.2403\n",
      "Epoch: 2, Loss: 1.0967\n",
      "Epoch: 2, Loss: 1.7470\n",
      "Epoch: 2, Loss: 1.0724\n",
      "Epoch: 2, Loss: 1.3222\n",
      "Epoch: 2, Loss: 1.0428\n",
      "Epoch: 3, Loss: 1.6281\n",
      "Epoch: 3, Loss: 0.6175\n",
      "Epoch: 3, Loss: 1.1524\n",
      "Epoch: 3, Loss: 0.9979\n",
      "Epoch: 3, Loss: 0.4153\n",
      "Epoch: 3, Loss: 1.7007\n",
      "Epoch: 3, Loss: 0.7351\n",
      "Epoch: 3, Loss: 1.7770\n",
      "Epoch: 3, Loss: 0.6515\n",
      "Epoch: 3, Loss: 0.8179\n",
      "Epoch: 3, Loss: 1.6786\n",
      "Epoch: 3, Loss: 0.7015\n",
      "Epoch: 3, Loss: 0.6954\n",
      "Epoch: 3, Loss: 1.6327\n",
      "Epoch: 3, Loss: 0.7936\n",
      "Epoch: 3, Loss: 0.2765\n",
      "Epoch: 3, Loss: 0.8488\n",
      "Epoch: 3, Loss: 1.1562\n",
      "Epoch: 3, Loss: 1.5438\n",
      "Epoch: 3, Loss: 1.4616\n",
      "Epoch: 3, Loss: 0.7909\n",
      "Epoch: 3, Loss: 1.5255\n",
      "Epoch: 3, Loss: 1.2467\n",
      "Epoch: 3, Loss: 1.4282\n",
      "Epoch: 3, Loss: 0.5876\n",
      "Epoch: 3, Loss: 0.6714\n",
      "Epoch: 3, Loss: 0.9367\n",
      "Epoch: 3, Loss: 1.7875\n",
      "Epoch: 3, Loss: 1.0573\n",
      "Epoch: 3, Loss: 1.3284\n",
      "Epoch: 3, Loss: 0.5272\n",
      "Epoch: 4, Loss: 1.4705\n",
      "Epoch: 4, Loss: 1.5042\n",
      "Epoch: 4, Loss: 0.7864\n",
      "Epoch: 4, Loss: 0.8075\n",
      "Epoch: 4, Loss: 1.8476\n",
      "Epoch: 4, Loss: 1.1379\n",
      "Epoch: 4, Loss: 0.2885\n",
      "Epoch: 4, Loss: 0.9640\n",
      "Epoch: 4, Loss: 1.1125\n",
      "Epoch: 4, Loss: 1.3640\n",
      "Epoch: 4, Loss: 0.6825\n",
      "Epoch: 4, Loss: 0.6435\n",
      "Epoch: 4, Loss: 0.7009\n",
      "Epoch: 4, Loss: 0.5556\n",
      "Epoch: 4, Loss: 0.4064\n",
      "Epoch: 4, Loss: 1.2969\n",
      "Epoch: 4, Loss: 0.9924\n",
      "Epoch: 4, Loss: 1.0070\n",
      "Epoch: 4, Loss: 0.9420\n",
      "Epoch: 4, Loss: 0.8995\n",
      "Epoch: 4, Loss: 1.4450\n",
      "Epoch: 4, Loss: 1.5430\n",
      "Epoch: 4, Loss: 0.3412\n",
      "Epoch: 4, Loss: 0.6514\n",
      "Epoch: 4, Loss: 1.1442\n",
      "Epoch: 4, Loss: 1.1454\n",
      "Epoch: 4, Loss: 1.4131\n",
      "Epoch: 4, Loss: 0.9203\n",
      "Epoch: 4, Loss: 1.1170\n",
      "Epoch: 4, Loss: 1.0180\n",
      "Epoch: 4, Loss: 0.6686\n",
      "Accuracy on Test Set: 51.85%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "# Define the KnowledgeGraph dataset class\n",
    "class KnowledgeGraphDataset(Dataset):\n",
    "    def __init__(self, triples, entity2idx, relation2idx):\n",
    "        self.triples = triples\n",
    "        self.entity2idx = entity2idx\n",
    "        self.relation2idx = relation2idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subject, relation, object_ = self.triples[idx]\n",
    "        return self.entity2idx[subject], self.relation2idx[relation], self.entity2idx[object_]\n",
    "\n",
    "# Create a list of triples (subject, relation, object)\n",
    "\n",
    "# Map entities and relations to numerical indices\n",
    "entities = list(set([subject for subject, _, _ in triples] + [object_ for _, _, object_ in triples]))\n",
    "entity2idx = {entity: idx for idx, entity in enumerate(entities)}\n",
    "relations = list(set([relation for _, relation, _ in triples]))\n",
    "relation2idx = {relation: idx for idx, relation in enumerate(relations)}\n",
    "\n",
    "# Split the data into training and testing sets using random split\n",
    "train_triples, test_triples = train_test_split(triples, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the KnowledgeGraph dataset\n",
    "train_dataset = KnowledgeGraphDataset(train_triples, entity2idx, relation2idx)\n",
    "test_dataset = KnowledgeGraphDataset(test_triples, entity2idx, relation2idx)\n",
    "\n",
    "# Define the dataloader for training and testing\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "# Set the hyperparameters\n",
    "num_entities = len(entities)\n",
    "num_relations = len(relations)\n",
    "embedding_dim = 3\n",
    "learning_rate = 0.02\n",
    "num_epochs = 5\n",
    "\n",
    "# Define the TransE model\n",
    "model = TransE(num_entities, num_relations, embedding_dim)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.MarginRankingLoss(margin=1.0)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Positive samples\n",
    "        positive_samples = torch.stack(batch, dim=1).long()\n",
    "\n",
    "        # Generate negative samples by corrupting the objects in positive samples\n",
    "        negative_samples = positive_samples.clone()\n",
    "        negative_samples[:, 2] = torch.randint(num_entities, size=(negative_samples.size(0),))\n",
    "\n",
    "        # Forward pass\n",
    "        pos_subject, pos_relation, pos_object = model(positive_samples)\n",
    "        neg_subject, neg_relation, neg_object = model(negative_samples)\n",
    "\n",
    "        # Compute the loss\n",
    "        target = torch.ones(pos_subject.size(0), 1)\n",
    "        loss = criterion(pos_subject + pos_relation - pos_object, neg_subject + neg_relation - neg_object, target)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"Epoch: {}, Loss: {:.4f}\".format(epoch, loss.item()))\n",
    "        \n",
    "# Evaluation loop\n",
    "# Evaluation loop\n",
    "with torch.no_grad():\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        # Forward pass\n",
    "        positive_samples = torch.stack(batch, dim=1).long()\n",
    "        subject, relation, object_ = model(positive_samples)\n",
    "\n",
    "        # Calculate distances\n",
    "        distances = torch.norm(subject + relation - object_, dim=1)\n",
    "\n",
    "        # Calculate ranks\n",
    "        _, indices = torch.sort(distances)\n",
    "        sorted_ranks = torch.arange(1, indices.size(0) + 1, device=indices.device)\n",
    "        ranks = sorted_ranks[indices]\n",
    "\n",
    "        # Count the number of correct predictions (lowest rank indicates highest similarity)\n",
    "        correct_predictions += (ranks == 1).sum().item()\n",
    "        total_samples += ranks.size(0)\n",
    "\n",
    "    accuracy = correct_predictions / total_samples\n",
    "    print(\"Accuracy on Test Set: {:.2f}%\".format(accuracy * 100))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To further analyze the performance, you may want to evaluate other metrics such as mean rank, mean reciprocal rank (MRR),\n",
    "# or hits at K. These metrics provide a more comprehensive understanding of the model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.4078\n",
      "Epoch: 0, Loss: 1.2694\n",
      "Epoch: 0, Loss: 1.7255\n",
      "Epoch: 0, Loss: 1.0912\n",
      "Epoch: 0, Loss: 1.1723\n",
      "Epoch: 0, Loss: 1.2063\n",
      "Epoch: 0, Loss: 1.3286\n",
      "Epoch: 0, Loss: 2.2007\n",
      "Epoch: 0, Loss: 0.9012\n",
      "Epoch: 0, Loss: 0.7931\n",
      "Epoch: 0, Loss: 0.7897\n",
      "Epoch: 0, Loss: 1.3881\n",
      "Epoch: 0, Loss: 1.0467\n",
      "Epoch: 0, Loss: 1.7327\n",
      "Epoch: 0, Loss: 0.6158\n",
      "Epoch: 0, Loss: 1.2265\n",
      "Epoch: 0, Loss: 1.1626\n",
      "Epoch: 0, Loss: 0.9960\n",
      "Epoch: 0, Loss: 1.4792\n",
      "Epoch: 0, Loss: 1.3182\n",
      "Epoch: 0, Loss: 0.8824\n",
      "Epoch: 0, Loss: 0.9238\n",
      "Epoch: 0, Loss: 0.6497\n",
      "Epoch: 0, Loss: 1.0115\n",
      "Epoch: 0, Loss: 1.2743\n",
      "Epoch: 0, Loss: 1.5525\n",
      "Epoch: 0, Loss: 0.9292\n",
      "Epoch: 0, Loss: 0.8554\n",
      "Epoch: 0, Loss: 1.5606\n",
      "Epoch: 0, Loss: 1.1482\n",
      "Epoch: 0, Loss: 0.3184\n",
      "Epoch: 1, Loss: 1.0569\n",
      "Epoch: 1, Loss: 1.4920\n",
      "Epoch: 1, Loss: 1.6145\n",
      "Epoch: 1, Loss: 0.7857\n",
      "Epoch: 1, Loss: 0.9676\n",
      "Epoch: 1, Loss: 1.2957\n",
      "Epoch: 1, Loss: 1.2854\n",
      "Epoch: 1, Loss: 1.0150\n",
      "Epoch: 1, Loss: 0.5461\n",
      "Epoch: 1, Loss: 0.4794\n",
      "Epoch: 1, Loss: 0.4789\n",
      "Epoch: 1, Loss: 0.8009\n",
      "Epoch: 1, Loss: 1.2840\n",
      "Epoch: 1, Loss: 0.8381\n",
      "Epoch: 1, Loss: 0.5531\n",
      "Epoch: 1, Loss: 2.0530\n",
      "Epoch: 1, Loss: 1.1005\n",
      "Epoch: 1, Loss: 0.7078\n",
      "Epoch: 1, Loss: 1.2602\n",
      "Epoch: 1, Loss: 0.5253\n",
      "Epoch: 1, Loss: 1.5493\n",
      "Epoch: 1, Loss: 1.4932\n",
      "Epoch: 1, Loss: 0.4551\n",
      "Epoch: 1, Loss: 0.7386\n",
      "Epoch: 1, Loss: 0.6811\n",
      "Epoch: 1, Loss: 1.7359\n",
      "Epoch: 1, Loss: 1.4633\n",
      "Epoch: 1, Loss: 1.1084\n",
      "Epoch: 1, Loss: 1.6339\n",
      "Epoch: 1, Loss: 1.0733\n",
      "Epoch: 1, Loss: 0.8654\n",
      "Epoch: 2, Loss: 1.0003\n",
      "Epoch: 2, Loss: 1.1061\n",
      "Epoch: 2, Loss: 1.5335\n",
      "Epoch: 2, Loss: 1.5230\n",
      "Epoch: 2, Loss: 1.7308\n",
      "Epoch: 2, Loss: 1.1107\n",
      "Epoch: 2, Loss: 1.4162\n",
      "Epoch: 2, Loss: 0.4583\n",
      "Epoch: 2, Loss: 1.3017\n",
      "Epoch: 2, Loss: 1.1219\n",
      "Epoch: 2, Loss: 1.7671\n",
      "Epoch: 2, Loss: 0.5245\n",
      "Epoch: 2, Loss: 1.0115\n",
      "Epoch: 2, Loss: 0.4898\n",
      "Epoch: 2, Loss: 1.6555\n",
      "Epoch: 2, Loss: 1.2478\n",
      "Epoch: 2, Loss: 1.4220\n",
      "Epoch: 2, Loss: 0.5480\n",
      "Epoch: 2, Loss: 0.9066\n",
      "Epoch: 2, Loss: 1.3310\n",
      "Epoch: 2, Loss: 1.0960\n",
      "Epoch: 2, Loss: 1.1306\n",
      "Epoch: 2, Loss: 0.3390\n",
      "Epoch: 2, Loss: 0.8087\n",
      "Epoch: 2, Loss: 0.5790\n",
      "Epoch: 2, Loss: 1.6146\n",
      "Epoch: 2, Loss: 1.0309\n",
      "Epoch: 2, Loss: 1.4753\n",
      "Epoch: 2, Loss: 0.8401\n",
      "Epoch: 2, Loss: 0.7125\n",
      "Epoch: 2, Loss: 0.6898\n",
      "Epoch: 3, Loss: 0.9790\n",
      "Epoch: 3, Loss: 1.7566\n",
      "Epoch: 3, Loss: 1.2012\n",
      "Epoch: 3, Loss: 1.9030\n",
      "Epoch: 3, Loss: 1.0235\n",
      "Epoch: 3, Loss: 1.1636\n",
      "Epoch: 3, Loss: 0.8519\n",
      "Epoch: 3, Loss: 0.8593\n",
      "Epoch: 3, Loss: 0.5461\n",
      "Epoch: 3, Loss: 1.1278\n",
      "Epoch: 3, Loss: 0.3730\n",
      "Epoch: 3, Loss: 1.2690\n",
      "Epoch: 3, Loss: 1.3737\n",
      "Epoch: 3, Loss: 1.1777\n",
      "Epoch: 3, Loss: 0.6325\n",
      "Epoch: 3, Loss: 0.4597\n",
      "Epoch: 3, Loss: 1.0901\n",
      "Epoch: 3, Loss: 1.1664\n",
      "Epoch: 3, Loss: 0.7452\n",
      "Epoch: 3, Loss: 0.6173\n",
      "Epoch: 3, Loss: 1.1166\n",
      "Epoch: 3, Loss: 0.8688\n",
      "Epoch: 3, Loss: 1.2072\n",
      "Epoch: 3, Loss: 1.3173\n",
      "Epoch: 3, Loss: 1.5654\n",
      "Epoch: 3, Loss: 0.8655\n",
      "Epoch: 3, Loss: 1.1376\n",
      "Epoch: 3, Loss: 0.9993\n",
      "Epoch: 3, Loss: 0.9049\n",
      "Epoch: 3, Loss: 0.5956\n",
      "Epoch: 3, Loss: 0.5025\n",
      "Epoch: 4, Loss: 0.1251\n",
      "Epoch: 4, Loss: 0.9696\n",
      "Epoch: 4, Loss: 0.8557\n",
      "Epoch: 4, Loss: 1.1630\n",
      "Epoch: 4, Loss: 0.8372\n",
      "Epoch: 4, Loss: 1.2491\n",
      "Epoch: 4, Loss: 0.7587\n",
      "Epoch: 4, Loss: 1.3880\n",
      "Epoch: 4, Loss: 1.2065\n",
      "Epoch: 4, Loss: 1.1657\n",
      "Epoch: 4, Loss: 0.4398\n",
      "Epoch: 4, Loss: 2.0799\n",
      "Epoch: 4, Loss: 0.7477\n",
      "Epoch: 4, Loss: 0.6091\n",
      "Epoch: 4, Loss: 0.1959\n",
      "Epoch: 4, Loss: 1.0036\n",
      "Epoch: 4, Loss: 1.3565\n",
      "Epoch: 4, Loss: 2.3221\n",
      "Epoch: 4, Loss: 1.3382\n",
      "Epoch: 4, Loss: 0.7510\n",
      "Epoch: 4, Loss: 1.1495\n",
      "Epoch: 4, Loss: 0.5577\n",
      "Epoch: 4, Loss: 0.4970\n",
      "Epoch: 4, Loss: 0.9260\n",
      "Epoch: 4, Loss: 1.0027\n",
      "Epoch: 4, Loss: 0.9567\n",
      "Epoch: 4, Loss: 0.8381\n",
      "Epoch: 4, Loss: 1.3406\n",
      "Epoch: 4, Loss: 1.6978\n",
      "Epoch: 4, Loss: 0.3349\n",
      "Epoch: 4, Loss: 1.1460\n",
      "Mean Rank on Test Set: 1.48\n",
      "MRR on Test Set: 0.7593\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "\n",
    "# Define the KnowledgeGraph dataset class\n",
    "class KnowledgeGraphDataset(Dataset):\n",
    "    def __init__(self, triples, entity2idx, relation2idx):\n",
    "        self.triples = triples\n",
    "        self.entity2idx = entity2idx\n",
    "        self.relation2idx = relation2idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.triples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subject, relation, object_ = self.triples[idx]\n",
    "        return self.entity2idx[subject], self.relation2idx[relation], self.entity2idx[object_]\n",
    "\n",
    "# Create a list of triples (subject, relation, object)\n",
    "\n",
    "# Map entities and relations to numerical indices\n",
    "entities = list(set([subject for subject, _, _ in triples] + [object_ for _, _, object_ in triples]))\n",
    "entity2idx = {entity: idx for idx, entity in enumerate(entities)}\n",
    "relations = list(set([relation for _, relation, _ in triples]))\n",
    "relation2idx = {relation: idx for idx, relation in enumerate(relations)}\n",
    "\n",
    "# Split the data into training and testing sets using random split\n",
    "train_triples, test_triples = train_test_split(triples, test_size=0.3, random_state=42)\n",
    "\n",
    "# Define the KnowledgeGraph dataset\n",
    "train_dataset = KnowledgeGraphDataset(train_triples, entity2idx, relation2idx)\n",
    "test_dataset = KnowledgeGraphDataset(test_triples, entity2idx, relation2idx)\n",
    "\n",
    "# Define the dataloader for training and testing\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=2, shuffle=False)\n",
    "\n",
    "# Set the hyperparameters\n",
    "num_entities = len(entities)\n",
    "num_relations = len(relations)\n",
    "embedding_dim = 3\n",
    "learning_rate = 0.02\n",
    "num_epochs = 5\n",
    "\n",
    "# Define the TransE model\n",
    "model = TransE(num_entities, num_relations, embedding_dim)\n",
    "\n",
    "# Define the loss function\n",
    "criterion = nn.MarginRankingLoss(margin=1.0)\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    for batch in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Positive samples\n",
    "        positive_samples = torch.stack(batch, dim=1).long()\n",
    "\n",
    "        # Generate negative samples by corrupting the objects in positive samples\n",
    "        negative_samples = positive_samples.clone()\n",
    "        negative_samples[:, 2] = torch.randint(num_entities, size=(negative_samples.size(0),))\n",
    "\n",
    "        # Forward pass\n",
    "        pos_subject, pos_relation, pos_object = model(positive_samples)\n",
    "        neg_subject, neg_relation, neg_object = model(negative_samples)\n",
    "\n",
    "        # Compute the loss\n",
    "        target = torch.ones(pos_subject.size(0), 1)\n",
    "        loss = criterion(pos_subject + pos_relation - pos_object, neg_subject + neg_relation - neg_object, target)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(\"Epoch: {}, Loss: {:.4f}\".format(epoch, loss.item()))\n",
    "        \n",
    "\n",
    "# Evaluation loop\n",
    "with torch.no_grad():\n",
    "    ranks = []\n",
    "    reciprocal_ranks = []\n",
    "\n",
    "    for batch in test_dataloader:\n",
    "        # Forward pass\n",
    "        positive_samples = torch.stack(batch, dim=1).long()\n",
    "        subject, relation, object_ = model(positive_samples)\n",
    "\n",
    "        # Calculate distances\n",
    "        distances = torch.norm(subject + relation - object_, dim=1)\n",
    "\n",
    "        # Calculate ranks\n",
    "        _, indices = torch.sort(distances)\n",
    "        sorted_ranks = torch.arange(1, indices.size(0) + 1, device=indices.device)\n",
    "        ranks.extend(sorted_ranks[indices].tolist())\n",
    "\n",
    "        # Calculate reciprocal ranks\n",
    "        reciprocal_ranks.extend((1.0 / sorted_ranks[indices]).tolist())\n",
    "\n",
    "    mean_rank = sum(ranks) / len(ranks)\n",
    "    mrr = sum(reciprocal_ranks) / len(reciprocal_ranks)\n",
    "\n",
    "    print(\"Mean Rank on Test Set: {:.2f}\".format(mean_rank))\n",
    "    print(\"MRR on Test Set: {:.4f}\".format(mrr))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Great! The mean rank of 1.5 indicates that, on average, the true positive samples are ranked at the 1st or 2nd position among all the samples. This suggests that the model is performing well in terms of ranking accuracy.\n",
    "\n",
    "#The Mean Reciprocal Rank (MRR) value of 0.75 also indicates good performance. It means that, on average, the reciprocal rank of the true positive sample is 0.75, reflecting that the correct answer is highly likely to be ranked within the top positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model to H5 file\n",
    "torch.save(model.state_dict(), \"model.h5\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model from H5 file\n",
    "model = TransE(num_entities, num_relations, embedding_dim)\n",
    "model.load_state_dict(torch.load(\"model.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransE(\n",
       "  (entity_embeddings): Embedding(110, 3)\n",
       "  (relation_embeddings): Embedding(13, 3)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the saved model\n",
    "model = TransE(num_entities, num_relations, embedding_dim)\n",
    "model.load_state_dict(torch.load(\"model.h5\"))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entities related to risk management: ['risk management', 'avoid', 'prompt list', 'scope baseline', 'monitor risk']\n"
     ]
    }
   ],
   "source": [
    "def recommend_related_entities(model, entity, k=5):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Get the embedding of the given entity\n",
    "    entity_idx = entity2idx[entity]\n",
    "    entity_embedding = model.entity_embeddings(torch.tensor([entity_idx]))\n",
    "\n",
    "    # Calculate the distance between the given entity and all other entities\n",
    "    distances = torch.norm(model.entity_embeddings.weight - entity_embedding, dim=1)\n",
    "\n",
    "    # Get the indices of the top k closest entities\n",
    "    _, indices = torch.topk(distances, k, largest=False)\n",
    "\n",
    "    # Convert the indices to entity names\n",
    "    recommendations = [entities[idx] for idx in indices]\n",
    "\n",
    "    return recommendations\n",
    "\n",
    "# Test the recommendation system\n",
    "entity = \"risk management\"\n",
    "recommendations = recommend_related_entities(model, entity)\n",
    "print(f\"Entities related to {entity}: {recommendations}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most likely relation between project document update and strategy for overall project risk is document\n"
     ]
    }
   ],
   "source": [
    "def predict_relation(model, entity1, entity2):\n",
    "    # Set the model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Get the embeddings of the given entities\n",
    "    entity1_idx = entity2idx[entity1]\n",
    "    entity1_embedding = model.entity_embeddings(torch.tensor([entity1_idx]))\n",
    "    entity2_idx = entity2idx[entity2]\n",
    "    entity2_embedding = model.entity_embeddings(torch.tensor([entity2_idx]))\n",
    "\n",
    "    # Calculate the difference between the two entity embeddings\n",
    "    diff = entity2_embedding - entity1_embedding\n",
    "\n",
    "    # Calculate the distance between the difference and all relation embeddings\n",
    "    distances = torch.norm(model.relation_embeddings.weight - diff, dim=1)\n",
    "\n",
    "    # Get the index of the closest relation\n",
    "    relation_idx = torch.argmin(distances).item()\n",
    "\n",
    "    # Convert the index to a relation name\n",
    "    relation = relations[relation_idx]\n",
    "\n",
    "    return relation\n",
    "\n",
    "# Test the prediction function\n",
    "entity1 = \"project document update\"\n",
    "entity2 = \"strategy for overall project risk\"\n",
    "relation = predict_relation(model, entity1, entity2)\n",
    "print(f\"The most likely relation between {entity1} and {entity2} is {relation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save entities and relations to a text file\n",
    "with open(\"entities.txt\", \"w\") as file:\n",
    "    for entity in entities:\n",
    "        file.write(f\"{entity}\\n\")\n",
    "\n",
    "with open(\"relations.txt\", \"w\") as file:\n",
    "    for relation in relations:\n",
    "        file.write(f\"{relation}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity2idx = {entity: idx for idx, entity in enumerate(entities)}\n",
    "import json\n",
    "\n",
    "# Save the entity2idx dictionary to a file\n",
    "with open(\"entity2idx.json\", \"w\") as file:\n",
    "    json.dump(entity2idx, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
